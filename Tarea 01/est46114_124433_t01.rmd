---
title: "Sesión 6: Análisis de Componentes Principales"
author: "Alejandra Lelo de Larrea Ibarra"
date: "10 de febrero de 2019."
header-includes:
  - \usepackage[spanish,mexico]{babel}
  - \usepackage{arydshln}
  - \usepackage{lscape}
  - \usepackage{rotating}
  - \usepackage{xcolor}
  - \usepackage{float}
  - \usepackage{framed}
output: 
  pdf_document:
    fig_caption: yes
    number_sections: true
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# par(mar=c(3.1,3.1,1.6,1.6))
setwd("~/Documents/ITAM_Maestria/04_Primavera_2019/02_EstMultivar_DatosCat/03_Ejercicios")
```


# Introducción 

Se tienen datos con los tipos de cambio reales (respecto a USD) de varias economias (periodo 1970-2010). El objetivo es implementar el procedimiento inferencial PCA considerando distribuciones iniciales no informativas para ($\mu$, $\Lambda$) y contestar lo siguiente: 

* ¿Qué economía tiene el mayor peso esperado en la descomposicion PCA?

* ¿Qué economía tiene la mayor consistencia en estimacion de los cjs correspondientes?


# Datos

```{r, message=FALSE,warning=FALSE}
# Se cargan los paquetes
library("fields")
library("mnormt")
library("MCMCpack")
library("actuar")
library("ggplot2")
library("kernlab")
library("tidyverse") 
library("readr") 
library("psych") 
library("mvtnorm")
library("MASS")
library("xlsx")
library("knitr")
```

```{r funciones_auxilares}
# Función para extraer modas
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

Leemos los datos correspondientes a los tipos de cambio de distintas economías. Se tienen 492 observaciones mensuales para 80 economías. 

```{r datos}
# Cargamos los datos)
data<-read.xlsx("../01_Notas_Ovando/est46114_s06_data.xls",sheetName = 'RealXR_Data')

# Obtenemos las dimensiones de los datos
dim(data)

# Extraemos las fechas 
fechas<-data$Date

data<-select(data,-Date)
```

Vemos que países están en la muestra: 
```{r paises}
# Vemos la lista de países 
colnames(data)

```

Graficamos las series de tiempo de los países para tener una idea de qué esté pasando. 

```{r seriesTiempo,fig.width=12,fig.height=14}
# SE parte el plot en 8 pedazos
par(mfrow=c(4,2))

# Se grafican series de tiempo de los tipos de cambio
ts.plot(as.ts(data[,1:10],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,11:20],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,21:30],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,31:40],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,41:50],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,51:60],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,61:70],start=c(1970,1),end=c(2010,12),frequency=12))
ts.plot(as.ts(data[,71:80],start=c(1970,1),end=c(2010,12),frequency=12))

```

# Inferencia de SPCA

Pensemos que para cada observación mensual se tiene que 
$$
\boldsymbol{X}_{j\cdot} \sim N_{p}(\boldsymbol{X}|\boldsymbol{\mu},\boldsymbol{\Lambda}),
$$
con $j=1,\ldots,80$ donde $\mu$ y $\Lambda$ son desconocidos. 


## Actualizacion bayesiana de parámetros 

El desconocimiento acerca de $(\boldsymbol{\mu},\boldsymbol{\Lambda})$ se expresa como 
$$
(\boldsymbol{\mu},\boldsymbol{\Lambda}) \sim \text{N-Wi}(\boldsymbol{\mu},\boldsymbol{\Lambda}|\boldsymbol{m}_0,s_0,a_0,\boldsymbol{B}_0),
$$

donde $\boldsymbol{m}_0=0,s_0=1/2,a_0=1,\boldsymbol{B}_0=I$; es decir, se tiene una distribución inicial no informativa.

De esta manera, la distribución posterior de $(\mu,\Lambda)$ a partir de la consolidación de la información contenida en los datos y la información complementaria está dada por 

$$
(\boldsymbol{\mu},\boldsymbol{\Lambda}|\boldsymbol{X}) \sim \text{N-Wi}(\boldsymbol{\mu},\boldsymbol{\Lambda}|\boldsymbol{m}_n,s_n,a_n,\boldsymbol{B}_n),
$$
con 
\begin{eqnarray*}
\boldsymbol{m}_n&=&\dfrac{s_0m_0+n\bar{x}}{s_n},\\
&&\\
s_n&=&s_0+n,\\
&&\\
a_n&=&a_0+\dfrac{n}{2},\\
&&\\
\boldsymbol{B}_n&=&\boldsymbol{B}_0+\dfrac{n}{2}\left[S+\dfrac{s_0}{s_n}(\bar{x}-m_0)(\bar{x}-m_0)'\right]
\end{eqnarray*}


```{r posterior, include=TRUE}

# Fijar hiperparámetros 
a0 <- 1
s0 <- 1/2
m0 <- matrix(0,ncol=1,nrow=ncol(data))
B0 <- diag(1,ncol=ncol(data),nrow=ncol(data)) 

# Función para calcular la posterior
gaussian.posterior <- function(data,m0,s0,a0,B0){
  
  # Media de los datos 
  xbar <- as.matrix(colMeans(data))
  
  # Mat. de var y cov de los datos. 
  S <- cov(data)
  
  # No. de obs. 
  n <- nrow(data)
  
  # No. de variables. 
  p <- ncol(data)
  
  # Parámetros actualizados de la posterior. 
  sn <- s0 + n
  an <- a0 + n/2
  mn <- (s0*m0 + n*xbar)/sn
  Bn <- B0 + (n/2)*(S + (s0/sn)*(xbar-m0)%*%t(xbar-m0))
  
  # Salida (parámetros actualizados)
  output <- list(mn=mn,sn=sn,an=an,Bn=Bn)
  return(output)
}

# Calculamos los hiperparams actualizados para la posterior 
output <- gaussian.posterior(data,m0,s0,a0,B0)

```

## Simulación 

Una vez realizada la actualización bayesiana de los hiperparámetros, simulamos $M$ observaciones para ($\mu$, $\Lambda$) como 
\begin{eqnarray}
\boldsymbol{\Lambda}^{(m)} & \sim & \text{Wi}(\boldsymbol{\Lambda}|a_n,\boldsymbol{B}_n), \nonumber \\
\boldsymbol{\mu}^{(m)}|\boldsymbol{\Lambda}^{(m)} & \sim & \text{N}(\boldsymbol{\mu}|\boldsymbol{m}_n,s_n\boldsymbol{\Lambda}^{(m)}). \nonumber
\end{eqnarray}

Con estos parámetros, obtenemos simulaciones de los eigenvalores y eigenvectores $(e_j^{(m)},\boldsymbol{v}^{(m)}_j)_{j=1}^{p},$ de la matriz de varianzas y covarianzas de los datos simulada en el paso anterior (inverso de $\Lambda^{(m)}$.

Por último, obtenemos simulaciones de las componentes principales como $\boldsymbol{c}_{j\cdot}^{(m)}=\boldsymbol{X}\boldsymbol{v}_{j}^{(m)}$. 

```{r simulacion}
# Se fija el no de simulaciones
M <- 10000

# Matriz para guardar medias
mu.sim <- matrix(NA,nrow=M, ncol=ncol(data))

# Arreglo para guardar precisiones 
Lambda.sim <- array(NA,dim=c(M,ncol(data),ncol(data)))

# Matriz para guardar valores propios. 
e.sim <- matrix(NA,nrow=M, ncol=ncol(data))

# Arreglo para gaurdar vectores propios
V.sim <- array(NA,dim=c(M,ncol(data),ncol(data)))

# Arreglo para guardar componentes principales
C.sim <- array(NA,dim=c(M,nrow(data),ncol(data)))

# Se convierten los datos a matriz. 
X <- as.matrix(data)

# En cada iteración:
for(m in 1:M){
  
  # Se simulan valores (mu,Lambda) 
  Lambda.sim[m,,] <- rWishart(1, output$an, output$Bn)
  mu.sim[m,] <- mvrnorm(1, mu=output$mn, Sigma=solve(output$sn*Lambda.sim[m,,]), tol = 1e-6)
  
  # Simulacion de eigenvalores y eigenvectores (e,V)
  eigen_aux <- eigen(solve(Lambda.sim[m,,])) 
  e.sim[m,] <- eigen_aux$values
  V.sim[m,,] <- eigen_aux$vectors
  
  # Simulación de componentes principales. 
  C.sim[m,,] <- X %*% V.sim[m,,]
}
```


# Resultados 

## Eigenvalores 

```{r,fig.height=12,fig.width=12}
multi.hist(e.sim)
```


## ¿Qué economía tiene el mayor peso esperado en la descomposición PCA? 

Los pesos de las componentes están representados por los eigenvectores. Utilizamos la moda de la distribución para obtener la matriz de eigenvectores promedio. 

```{r PesosMax}
# Estimador puntual de la matriz de eigenvectores. 
V.mode<-matrix(NA,ncol(data),ncol(data))

# Se extrae la moda para cada elemento de la matriz de eigenvectores
for(i in 1:ncol(data)){
  
  for(j in 1:ncol(data)){
    
    V.mode[i,j]<-getmode(V.sim[,i,j])
  }
}

colnames(V.mode)<-paste("PC",1:ncol(data),sep="_")
rownames(V.mode)<-colnames(data)

# Se busca el peso más grande en cada una de las componentes. 
peso_max<-data_frame(CP=colnames(V.mode), 
                     Economia=apply(V.mode,2,function(x){rownames(V.mode)[which.max(x)]}))

kable(cbind(peso_max[1:20,],peso_max[21:40,],peso_max[41:60,],peso_max[61:80,]),
      type='latex',
      caption='Economia con mayor peso por componente principal')    

# Tabla de frecuencias para pesos por país
frec_peso_max<-table(peso_max$Economia)
frec_peso_max<-data_frame(Economia=names(frec_peso_max),
                         Frecuencia=frec_peso_max)
kable(cbind(frec_peso_max[1:ceiling(nrow(frec_peso_max)/2),],
            frec_peso_max[(ceiling(nrow(frec_peso_max)/2)+1):nrow(frec_peso_max),]),
      type='latex',
      caption='Frecuencias de Economías con Mayor Peso')

```

## ¿Qué economía tiene la mayor consistencia en estimacion de los cjs correspondientes?

```{r}
# Varianza de los eigenvectores. 
V.var<-matrix(NA,ncol(data),ncol(data))

# Se calcula la varianza de cada elemento de los eigenvectores
for(i in 1:ncol(data)){
  
  for(j in 1:ncol(data)){
    
    V.var[i,j]<-var(C.sim[,i,j],na.rm=TRUE)
  }
}

colnames(V.var)<-paste("PC",1:ncol(data),sep="_")
rownames(V.var)<-colnames(data)

# Se busca el menor varianza en cada una de las componentes. 
var_min<-data_frame(CP=colnames(V.var), 
                     EcoVarMin=apply(V.var,2,function(x){rownames(V.var)[which.min(x)]}))

kable(cbind(var_min[1:20,],var_min[21:40,],var_min[41:60,],var_min[61:80,]),
      type='latex',
      caption='Economia con Menor Varianza por Componente Principal')    
    

# Tabla de frecuencias para pesos por país
frec_var_min<-table(var_min$EcoVarMin)
frec_var_min<-data_frame(Economia=names(frec_var_min),
                         Frecuencia=frec_var_min)
kable(cbind(frec_var_min[1:ceiling(nrow(frec_var_min)/2),],
            frec_var_min[(ceiling(nrow(frec_var_min)/2)+1):nrow(frec_var_min),]),
      type='latex',
      caption='Frecuencia de Economías con menor varianza')

```

